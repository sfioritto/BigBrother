import os
import tornado.ioloop
import tornado.web
import json
from tornado.web import url, RequestHandler, StaticFileHandler
from models import Whorl, WhorlIdentity, engine, Session, Identity, Stat
from hashlib import sha512
from sqlalchemy.orm import joinedload
from sqlalchemy.orm.exc import NoResultFound
from sqlalchemy.sql.expression import asc
from operator import mul
from collections import defaultdict

class Application(tornado.web.Application):

    def __init__(self):

        settings = {
            "static_path": os.path.join(os.path.dirname(__file__), "static")
            }


        handlers = [
            (r"/identify", Identify),
            (r"/tag", Tag),
            (r"/(tester\.html)", StaticFileHandler,
             dict(path=settings['static_path']))]


        tornado.web.Application.__init__(self, handlers, **settings)
        


class BaseHandler(RequestHandler):

    def __init__(self, *args, **kwargs):
        self.session = Session()
        RequestHandler.__init__(self, *args, **kwargs)


    def get_whorls(self, rawdata):

        whorls = []
        hashes = [hashed for key, value, hashed in create_hashes(dict(rawdata))]
        whorls = self.session.query(Whorl).\
                filter(Whorl.hashed.in_(hashes)).\
                all()

                #TODO: if the number of users grows large, we need to limit
                # the whorls we consider, because otherwise the set of users we need
                # to consider gets too large, and the memory and computing requirements
                # will grow too quickly. So we could do something like this:
                #
                #order_by(asc(Whorl.count)).\
                #limit(top)
                #
                # this only looks at rare whorls. This may not be the best solution. When the data
                # is sparse, if a player switches browsers there is very little or no overlap with
                # the whorls generated by the previous browser with this method.
            
        return whorls
        
    def create_get_whorls(self, rawdata):
        
        whorls = []
        
        for key, value, hashed in create_hashes(dict(rawdata)):
            try:
                whorl = self.session.query(Whorl).filter_by(hashed=hashed).one()

            except NoResultFound:
                whorl = Whorl(hashed=hashed, key=key, value=value)
                self.session.add(whorl)
                self.session.flush()
                
            whorls.append(whorl)

        return whorls



    def finish(self, *args, **kwargs):
        return RequestHandler.finish(self, *args, **kwargs)


def create_hashes(whorls, prefix=None):
    
    hashes = []

    for key, value in whorls.items():

        if prefix:
            key = prefix + ":" + key
            
        if type(value) == dict:
            hashes.extend(create_hashes(value, prefix=key))
            
        elif type(value) == list:
            for item in value:
                hashes.extend(create_hashes(item, prefix=key))
                
        else:
            hashes.append((key,
                            value,
                            sha512(key + str(value)).hexdigest()))

    return hashes


def learn(whorls, identity, session):
    
    """
    increment the count for whorlID probability, whorl, total_visits
    and identity.
    """

    identity.count = identity.count + 1
    total_visits = session.query(Stat).filter_by(key="total_visits").one()
    total_visits.value = total_visits.value + 1

    for whorl in whorls:
        whorl.count = whorl.count + 1
        try:
            wgi = session.query(WhorlIdentity).filter_by(whorl_hashed=whorl.hashed).filter_by(identity_id=identity.id).one()
            wgi.count = wgi.count + 1
            
        except NoResultFound:
            wgi = WhorlIdentity(whorl_hashed=whorl.hashed,
                                     identity_id = identity.id)
            session.add(wgi)
            session.flush()
                

def build_raw_data(request, partial):

        rawdata = []
        rawdata.extend(partial.items())
        rawdata.append(("supports http 1.1", request.supports_http_1_1()))
        rawdata.extend(request.headers.items())

        return rawdata


def get_user(username, session):

    try:
        return session.query(Identity).filter_by(username=username).one()
    except NoResultFound:
        identity = Identity(username=username)
        session.add(identity)
        session.flush()
        return identity
        

class Tag(BaseHandler):

    def post(self):
        partial = json.loads(self.request.body)
        rawdata = build_raw_data(self.request, partial)
        username = partial["username"]
        identity = get_user(username, self.session)
        whorls = self.create_get_whorls(rawdata)
        learn(whorls, identity, self.session)
        self.session.commit()


class Identify(BaseHandler):

    def post(self):
        partial = json.loads(self.request.body) # as in a partial fingerprint
        rawdata = build_raw_data(self.request, partial)
        whorls = self.get_whorls(rawdata)
        identity = identify_from(whorls, self.session)

        if identity:
            self.write(str(identity.username))
        else:
            self.write("I dunno.")


def identify_from(whorls, session):
    
    stats = stats_obj(session)
    minprob = float(1) / stats["total_visits"]
    whorl_hashes = list(set([whorl.hashed for whorl in whorls]))

    # this is a dictionary of dictionaries. The inner dictionaries
    # contain probabilities of the whorl given the user.
    whorlids = defaultdict(lambda : defaultdict(lambda : minprob))
    for wid in session.query(WhorlIdentity).\
        filter(WhorlIdentity.whorl_hashed.in_(whorl_hashes)).\
        all():

        whorlids[wid.identity][wid.whorl_hashed] =\
            min(1, float(wid.count) / wid.identity.count)

    # The probabilities above are then used to create a list
    # of probabilities per user for every whorl passed in.
    # The inner dictionary above defaults to a reasonable
    # minimum if we've never seen a whorl for a given user
    givenid = defaultdict(list)
    for identity, idprobs in whorlids.items():
        for whorl in whorls:
            givenid[identity].append(idprobs[whorl.hashed])

    # These are all the probabilities put into a list of tuples so
    # it can be sorted by probability.
    probs = [(\
               # calculate the posterior probability p(whorl|identity)p(identity)
               reduce(mul, idprobs) * (float(identity.count) / stats["total_visits"]),\

               # identity id as a tie breaker in sorting. this is arbitrary. If there
               # is a tie, we just guess. could put a random number here I suppose.
               identity.id,\

               # the identity tied to this probability.
               identity) \
               
               for identity, idprobs in givenid.items()]

    probs.sort()
    return probs[-1][2] # the most likely identity (third element is the identity)
    
    
def stats_obj(session):

    return dict([(s.key, s.value) for s in session.query(Stat).all()])
        

if __name__ == "__main__":
    application = Application()
    application.listen(8080)
    tornado.ioloop.IOLoop.instance().start()
