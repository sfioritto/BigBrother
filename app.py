import os
import tornado.ioloop
import tornado.web
import json
from tornado.web import url, RequestHandler, StaticFileHandler
from models import Whorl, WhorlIdentity, engine, Session, Identity, Stat
from hashlib import sha512
from sqlalchemy.orm import joinedload
from sqlalchemy.orm.exc import NoResultFound
from sqlalchemy.sql.expression import asc
from operator import mul


class Application(tornado.web.Application):

    def __init__(self):

        settings = {
            "static_path": os.path.join(os.path.dirname(__file__), "static")
            }


        handlers = [
            (r"/identify", Identify),
            (r"/tag", Tag),
            (r"/(tester\.html)", StaticFileHandler,
             dict(path=settings['static_path']))]


        tornado.web.Application.__init__(self, handlers, **settings)
        


class BaseHandler(RequestHandler):

    def __init__(self, *args, **kwargs):
        self.session = Session()
        RequestHandler.__init__(self, *args, **kwargs)


    def get_whorls(self, rawdata):

        whorls = []
        hashes = [hashed for key, value, hashed in create_hashes(dict(rawdata))]
        whorls = self.session.query(Whorl).\
                filter(Whorl.hashed.in_(hashes)).\
                all()

                #TODO: if the number of users grows large, we need to limit
                # the whorls we consider, because otherwise the set of users we need
                # to consider gets too large, and the memory and computing requirements
                # will grow too quickly. So we could do something like this:
                #
                #order_by(asc(Whorl.count)).\
                #limit(top)
                #
                # this only looks at rare whorls. This may not be the best solution. When the data
                # is sparse, if a player switches browsers there is very little or no overlap with
                # the whorls generated by the previous browser with this method.
            
        return whorls
        
    def create_get_whorls(self, rawdata):
        
        whorls = []
        
        for key, value, hashed in create_hashes(dict(rawdata)):
            try:
                whorl = self.session.query(Whorl).filter_by(hashed=hashed).one()

            except NoResultFound:
                whorl = Whorl(hashed=hashed, key=key, value=value)
                self.session.add(whorl)
                self.session.flush()
                
            whorls.append(whorl)

        return whorls



    def finish(self, *args, **kwargs):
        return RequestHandler.finish(self, *args, **kwargs)


def create_hashes(whorls, prefix=None):
    
    hashes = []

    for key, value in whorls.items():

        if prefix:
            key = prefix + ":" + key
            
        if type(value) == dict:
            hashes.extend(create_hashes(value, prefix=key))
            
        elif type(value) == list:
            for item in value:
                hashes.extend(create_hashes(item, prefix=key))
                
        else:
            hashes.append((key,
                            value,
                            sha512(key + str(value)).hexdigest()))

    return hashes


def learn(whorls, identity, session):
    
    """
    increment the count for whorlGivenId probability and whorl
    """
    
    for whorl in whorls:
        whorl.count = whorl.count + 1
        try:
            wgi = session.query(WhorlIdentity).filter_by(whorl_hashed=whorl.hashed).filter_by(identity_id=identity.id).one()
            wgi.count = wgi.count + 1
            
        except NoResultFound:
            wgi = WhorlIdentity(whorl_hashed=whorl.hashed,
                                     identity_id = identity.id)
            session.add(wgi)
            session.flush()
                

def build_raw_data(request, partial):

        rawdata = []
        rawdata.extend(partial.items())
        rawdata.append(("supports http 1.1", request.supports_http_1_1()))
        rawdata.extend(request.headers.items())

        return rawdata


def get_user(username, session):

    try:
        return session.query(Identity).filter_by(username=username).one()
    except NoResultFound:
        session.add(Identity(username=username))
        session.flush()
        

class Tag(BaseHandler):

    def post(self):
        partial = json.loads(self.request.body)
        rawdata = build_raw_data(self.request, partial)
        username = partial["username"]
        identity = get_user(username, self.session)
        whorls = self.create_get_whorls(rawdata)
        learn(whorls, identity, self.session)
        total_visits = self.session.query(Stat).filter_by(key="total_visits").one()
        total_visits.value = total_visits.value + 1
        self.session.commit()


class Identify(BaseHandler):

    def post(self):
        partial = json.loads(self.request.body) # as in a partial fingerprint
        rawdata = build_raw_data(self.request, partial)
        whorls = self.get_whorls(rawdata)
        identity = identify_from(whorls, self.session)

        if identity:
            self.write(str(identity))
        else:
            self.write("I dunno.")


def identify_from(whorls, session):
    whorl_hashes = list(set([whorl.hashed for whorl in whorls]))

    identities = session.query(Identity).\
        options(joinedload("whorl_identities")).\
        filter(WhorlIdentity.whorl_hashed.in_(whorl_hashes)).\
        all()

    stats = stats_obj(session)

    probs = []
    for identity in identities:
        prob = \
            reduce(mul, [float(wi.count) / identity.count for wi in identity.whorl_identities]) *\
            (float(identity.count) / stats["total_visits"])
        probs.append((identity, prob))

    print probs
    return
    
def stats_obj(session):

    return dict([(s.key, s.value) for s in session.query(Stat).all()])
        

if __name__ == "__main__":
    application = Application()
    application.listen(8080)
    tornado.ioloop.IOLoop.instance().start()
